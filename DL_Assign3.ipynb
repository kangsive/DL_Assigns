{"cells":[{"cell_type":"markdown","metadata":{"id":"E3sue2waNSmw"},"source":["### Question 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhPcfnfDSzjO"},"outputs":[],"source":["def get_output_size(input, kernel_size, stride, padding):\n","    _, _, w, h = input.shape\n","    output_width = (w+2*padding-kernel_size)//stride + 1\n","    output_height = (h+2*padding-kernel_size)//stride + 1\n","    return (output_width, output_height)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFcxfg2MTB4A"},"outputs":[],"source":["import torch.nn.functional as F\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1701534561003,"user":{"displayName":"庞定康","userId":"14688531517868636068"},"user_tz":-60},"id":"LWpezvlSTGv5","outputId":"97f05725-ae48-4ddd-e425-5ec8c923e6d4"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Test\n","kernel_size, stride, padding = 5, 2, 2\n","filters = torch.randn(8, 4, kernel_size, kernel_size)\n","inputs = torch.randn(1, 4, 26, 54)\n","output = F.conv2d(inputs, filters, stride=stride, padding=padding)\n","osize = get_output_size(inputs, kernel_size, stride=stride, padding=padding)\n","(output.shape[-2], output.shape[-1]) == (osize[-2], osize[-1])"]},{"cell_type":"markdown","metadata":{"id":"Fp1RLw9iNY8X"},"source":["### Question 6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5ngFUOCpVkv"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","\n","class Conv2DFunc(torch.autograd.Function):\n","  @staticmethod\n","  def forward(ctx, X, kernel, stride=1, padding=1):\n","    \"\"\"\n","    Computation Graph: X-(unfold)-> U -(multiply W)-> Y' -(reshape)-> Y\n","    \"\"\"\n","    b, c, h, w = X.shape\n","    kn, _, kh, kw = kernel.shape # kn: nr of kernels, kh: kernel height, kw: kernel width\n","    oh, ow = (h+2*padding-kh)//stride + 1, (w+2*padding-kw)//stride + 1\n","\n","    U = F.unfold(X, (kh, kw), stride=stride, padding=padding)\n","\n","    assert oh*ow == U.shape[2]\n","\n","    U = U.transpose(1, 2)   # (b, k, p) --> (b, p, k)\n","    W = kernel.view(kn, -1).t()   # (nr_kernels, nr_input_channels, kernel_height, kernel_width) --> (k, nr_kernels)\n","    Y_prime = U.matmul(W)   # (b, p, nr_kernels), nr_kernels = nr_output_channels\n","    Y_prime = Y_prime.transpose(1, 2) # (b, oc, p)\n","\n","    Y = Y_prime.reshape(b, kn, oh, ow)   # (b, oc, oh, ow)\n","\n","    ctx.hw = (h, w)\n","    ctx.kshape = (kn, c, kh, kw)\n","    ctx.sp = (stride, padding)\n","    ctx.UW = (U, W)\n","    ctx.yprime_shape = Y_prime.shape\n","\n","    return Y\n","\n","  @staticmethod\n","  def backward(ctx, grad_Y):\n","    (h, w), (kn, c, kh, kw), (stride, padding), (U, W), Y_prime_size = ctx.hw, \\\n","    ctx.kshape, ctx.sp, ctx.UW, ctx.yprime_shape\n","\n","    grad_Y_prime = grad_Y.reshape(Y_prime_size).transpose(1, 2)\n","\n","    kernel_grad = U.transpose(1, 2).matmul(grad_Y_prime)\n","    kernel_grad = kernel_grad.sum(dim=0)\n","    kernel_grad = kernel_grad.t().reshape(kn, c, kh, kw)\n","\n","    grad_U = grad_Y_prime.matmul(W.t())\n","    grad_U = grad_U.transpose(1, 2)\n","\n","    input_batch_grad = F.fold(grad_U, (h, w), (kh, kw), stride=stride, padding=padding)\n","\n","    return input_batch_grad, kernel_grad, None, None\n","\n","\n","input_batch = torch.randn(16, 3, 32, 32, requires_grad=True)\n","kernel = torch.randn(2, 3, 4, 5, requires_grad=True)\n","output = Conv2DFunc.apply(input_batch, kernel)\n","output.backward(torch.ones_like(output))"]},{"cell_type":"markdown","metadata":{"id":"bgbVy1mgNoHm"},"source":["### Question 7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6R0bOMD5NrZH"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torchvision.datasets import MNIST\n","\n","# Set random seed for reproducibility\n","torch.manual_seed(42)\n","\n","# Define the transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","# Download MNIST dataset\n","train = MNIST(root='./data', train=True, download=True, transform=transform)\n","test = MNIST(root='./data', train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRcxBDlEQgEy"},"outputs":[],"source":["# Split training data into training and validation sets\n","train_size = 50000\n","val_size = len(train) - train_size\n","\n","train_dataset, val_dataset = torch.utils.data.random_split(train, [train_size, val_size])\n","\n","# Create tensors for training instances and labels\n","train_instances = torch.stack([instance for instance, _ in train_dataset])\n","train_labels = torch.tensor([label for _, label in train_dataset])\n","\n","val_instances = torch.stack([instance for instance, _ in val_dataset])\n","val_labels = torch.tensor([label for _, label in val_dataset])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yBS7bwdVcWk"},"outputs":[],"source":["# Define Model\n","model = None\n","\n","# Define Loss function\n","loss_func = None\n","\n","# Define Optimizer\n","optimizer = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQxSYNlxU7F8"},"outputs":[],"source":["# Hypermarameters\n","batch_size = 16\n","num_epochs = 10\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","\n","    # Training phase\n","    model.train()\n","    for i in range(0, len(train_instances), batch_size):\n","        batch_instances = train_instances[i:i + batch_size]\n","        batch_labels = train_labels[i:i + batch_size]\n","\n","        # Forward pass\n","        outputs = model(batch_instances)\n","\n","        # Compute loss\n","        loss = loss_func(outputs, batch_labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print training statistics\n","        if (i + 1) % 100 == 0:\n","            print(f'Epoch [{epoch + 1}/{num_epochs}], \\\n","                   Step [{i + 1}/{len(train_instances)}],\\\n","                   Loss: {loss.item():.4f}')\n","\n","    # Validation phase\n","    model.eval()\n","    with torch.no_grad():\n","        # Use the entire validation set at once\n","        val_outputs = model(val_instances)\n","\n","        # Compute accuracy\n","        _, predicted = torch.max(val_outputs, 1)\n","        correct = (predicted == val_labels).sum().item()\n","        accuracy = correct / len(val_labels)\n","        print(f'Epoch [{epoch + 1}/{num_epochs}],\\\n","              Validation Accuracy: {100 * accuracy:.2f}%')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOde5rCPeSn6ZwDt3cu8hFk","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
